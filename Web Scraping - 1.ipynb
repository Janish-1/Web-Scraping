{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66866204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html-to-json in d:\\anaconda\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (from html-to-json) (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4->html-to-json) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4->html-to-json) (2.3.1)\n",
      "Requirement already satisfied: xmltojson in d:\\anaconda\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: xmltodict<0.13.0,>=0.12.0 in d:\\anaconda\\lib\\site-packages (from xmltojson) (0.12.0)\n",
      "Requirement already satisfied: utils in d:\\anaconda\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement json (from versions: none)\n",
      "ERROR: No matching distribution found for json\n"
     ]
    }
   ],
   "source": [
    "!pip install html-to-json\n",
    "!pip install xmltojson\n",
    "!pip install utils\n",
    "!pip install json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b8b4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import chromedriver_autoinstaller as chromedriver\n",
    "import time\n",
    "import html_to_json\n",
    "import json\n",
    "chromedriver.install()\n",
    "\n",
    "driver = webdriver.Chrome()# Adding the chromedriverpath here \n",
    "links = []\n",
    "url = 'https://www.topuniversities.com/university-rankings/world-university-rankings/2023'\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath('//*[@id=\"block-tu-d8-content\"]/div/article/div/div/div[3]/div/div[1]/div/div[3]/div[4]/div[1]/div[2]').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"block-tu-d8-content\"]/div/article/div/div/div[3]/div/div[1]/div/div[3]/div[4]/div[1]/div[2]/div[2]/div[4]').click()\n",
    "time.sleep(2)\n",
    "elems = driver.find_elements_by_class_name('uni-link')\n",
    "for elem in elems:\n",
    "    links.append(elem.get_attribute(\"href\"))\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae48a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import chromedriver_autoinstaller as chromedriver\n",
    "import time\n",
    "import html_to_json\n",
    "import json\n",
    "chromedriver.install()\n",
    "driver = webdriver.Chrome()# Adding the chromedriverpath here \n",
    "\n",
    "for i in range(len(links)):\n",
    "    filename = \"WebsiteData\"+str(i)\n",
    "    driver.get(links[i])\n",
    "    try:\n",
    "        html_source1 = driver.find_element_by_xpath('//*[@id=\"p2-overview\"]/div[2]/div')\n",
    "        hs1 = html_source1.get_attribute(\"innerHTML\")\n",
    "        oj1 = html_to_json.convert(hs1)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj1, json_file,indent=4,separators=(',',': '))\n",
    "        html_source2 = driver.find_element_by_xpath('//*[@id=\"p2-university-information\"]')\n",
    "        hs2 = html_source2.get_attribute(\"innerHTML\")\n",
    "        oj2 = html_to_json.convert(hs2)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj2, json_file,indent=4,separators=(',',': '))\n",
    "        html_source3 = driver.find_element_by_xpath('//*[@id=\"p2-tuition-fee-and-scholarships\"]')\n",
    "        hs3 = html_source3.get_attribute(\"innerHTML\")\n",
    "        oj3 = html_to_json.convert(hs3)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj3, json_file,indent=4,separators=(',',': '))\n",
    "        html_source4 = driver.find_element_by_xpath('//*[@id=\"p2-rankings\"]')\n",
    "        hs4 = html_source4.get_attribute(\"innerHTML\")\n",
    "        oj4 = html_to_json.convert(hs4)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj4, json_file,indent=4,separators=(',',': '))\n",
    "        html_source5 = driver.find_element_by_xpath('//*[@id=\"p2-campus-location\"]')\n",
    "        hs5 = html_source5.get_attribute(\"innerHTML\")\n",
    "        oj5 = html_to_json.convert(hs5)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj5, json_file,indent=4,separators=(',',': '))\n",
    "        html_source6 = driver.find_element_by_xpath('//*[@id=\"block-tu-d8-content\"]/div/article/div/div[2]/div/div/div[8]')\n",
    "        hs6 = html_source6.get_attribute(\"innerHTML\")\n",
    "        oj6 = html_to_json.convert(hs6)\n",
    "        with open(filename, 'a') as json_file:\n",
    "            json.dump(oj6, json_file,indent=4,separators=(',',': '))\n",
    "    except:\n",
    "        continue\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145a328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
